{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze A/B Test Results\n",
    "### by Ibrahim Olayiwola\n",
    "\n",
    "## Table of contents.\n",
    "\n",
    "- [Introduction](#intro)\n",
    "- [Part I - Probability](#probability)\n",
    "- [Part II - A/B Test](#ab_test)\n",
    "- [Part III - Regression](#regression)\n",
    "- [Part IV - Conclusions](#conclusions)\n",
    "\n",
    "\n",
    "<a id='intro'></a>\n",
    "### Introduction\n",
    ">A/B tests are very commonly performed by to test whether a changed version of a webpage brings about more conversion in users.\n",
    "For this project, I will be working to understand the results of an A/B test run by an e-commerce website. The goal is to work through this notebook to help the company understand if they should implement the new page, keep the old page, or perhaps run the experiment longer to make their decision.\n",
    "\n",
    ">The A/B test has been carried out and what remains is for me to analyze it. The reason I'm doing this analysis is to help an e-commerce company know if they should implement a new page, keep the old page, or perhaps run the experiment longer to make a decision. The A/B test results is save in a csv file name ab_data.\n",
    "\n",
    "\n",
    "<a id='probability'></a>\n",
    "### Part I - Probability\n",
    "\n",
    ">In this part, we'd calculate some probabilities, but to get started, we'd import our libraries and do some preliminary cleaning of the data. We'd also copy our data to use for the analysis to preserve our original dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Setting seed so as to get uniform answer when another analyst carries out this test.\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Now, the data will be read in and stored in a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>group</th>\n",
       "      <th>landing_page</th>\n",
       "      <th>converted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>851104</td>\n",
       "      <td>2017-01-21 22:11:48.556739</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>804228</td>\n",
       "      <td>2017-01-12 08:01:45.159739</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>661590</td>\n",
       "      <td>2017-01-11 16:55:06.154213</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>853541</td>\n",
       "      <td>2017-01-08 18:28:03.143765</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>864975</td>\n",
       "      <td>2017-01-21 01:52:26.210827</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                   timestamp      group landing_page  converted\n",
       "0   851104  2017-01-21 22:11:48.556739    control     old_page          0\n",
       "1   804228  2017-01-12 08:01:45.159739    control     old_page          0\n",
       "2   661590  2017-01-11 16:55:06.154213  treatment     new_page          0\n",
       "3   853541  2017-01-08 18:28:03.143765  treatment     new_page          0\n",
       "4   864975  2017-01-21 01:52:26.210827    control     old_page          1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('ab_data.csv')\n",
    "\n",
    "# Checking the first 5 rows of the dataframe.\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">From the above rows, we can see that;\n",
    "- There are 5 columns in the dataset.\n",
    "- The users were divided into two groups, the control group which were shown the old landing page and the treatment group which were shown the new landing page.\n",
    "- There is also a column that shows if a user was converted or not based on the page they were shown.\n",
    "\n",
    "Next, I would explore the dataset to know more about it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "294478"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of rows in the dataset\n",
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">There are two hundred and ninety-four thousand, four hundred and seventy-eight (294,478) rows in the dataset.\n",
    "\n",
    ">Next is to check the number of unique users and other unique details about the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id         290584\n",
       "timestamp       294478\n",
       "group                2\n",
       "landing_page         2\n",
       "converted            2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unique details\n",
    "df.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> So, from the output above we can say that\n",
    "- Out of 294478 users, 290584 are unique meaning 3894 are duplicate of some users.\n",
    "- The users were divided into two main groups, the control group and the treatment group.\n",
    "- There are two landing pages, the old page and the new page.\n",
    "- Users were either converted or not.\n",
    "\n",
    "Now, we'd check the proportion of users converted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11965919355605512"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Proportion of users converted\n",
    "df.converted.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Approximately 12% of users were converted. \n",
    "\n",
    "> From basic knowledge and from the data thats been previewed, we know that the treatment group is meant to match the new landing page and the control group is meant to match the old landing page. However, there might be some errors so we would check if some users in a group doesn't match the page they were supposed to match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3893"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The number of times the new_page and treatment don't match.\n",
    "df.query('(group != \"treatment\" and landing_page == \"new_page\") or (group == \"treatment\" and landing_page != \"new_page\")').user_id.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The number of time the pages and the landing page doesn't match is 3893.\n",
    "\n",
    ">Now, we would check for missing values in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id         False\n",
       "timestamp       False\n",
       "group           False\n",
       "landing_page    False\n",
       "converted       False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for missing values.\n",
    "df.isna().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> From the above, there are no missing values in the dataset, and since we're not sure about the 3893 pages and group that does not match, we would drop the rows which the values does not match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "290585"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dropping rows in which the treatment does not match the landing page and save in df2.\n",
    "df_c = df.query('group == \"control\" and landing_page == \"old_page\"')\n",
    "df_t = df.query('group == \"treatment\" and landing_page == \"new_page\"')\n",
    "df2 = df_c.append(df_t)\n",
    "df2.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">After dropping, the number of rows decreased to 290585. Next, we'd double check for values that don't match and check for duplicate values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Double checking for pages and group that doesn't match.\n",
    "df2[((df2['group'] == 'treatment') == (df2['landing_page'] == 'new_page')) == False].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>group</th>\n",
       "      <th>landing_page</th>\n",
       "      <th>converted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2893</th>\n",
       "      <td>773192</td>\n",
       "      <td>2017-01-14 02:55:59.590927</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id                   timestamp      group landing_page  converted\n",
       "2893   773192  2017-01-14 02:55:59.590927  treatment     new_page          0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for duplicate rows\n",
    "# Checking for duplicates user_id\n",
    "df2[df2.duplicated(['user_id'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">There is a duplicate row of user_id 773192. Let's check for more information on the duplicate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>group</th>\n",
       "      <th>landing_page</th>\n",
       "      <th>converted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1899</th>\n",
       "      <td>773192</td>\n",
       "      <td>2017-01-09 05:37:58.781806</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2893</th>\n",
       "      <td>773192</td>\n",
       "      <td>2017-01-14 02:55:59.590927</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id                   timestamp      group landing_page  converted\n",
       "1899   773192  2017-01-09 05:37:58.781806  treatment     new_page          0\n",
       "2893   773192  2017-01-14 02:55:59.590927  treatment     new_page          0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.query('user_id == \"773192\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The duplicated row is 1899 and it has almost same information except for the timestamp. One row should be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping row 1899\n",
    "df2 = df2.drop([1899])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 290584 entries, 0 to 294477\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count   Dtype \n",
      "---  ------        --------------   ----- \n",
      " 0   user_id       290584 non-null  int64 \n",
      " 1   timestamp     290584 non-null  object\n",
      " 2   group         290584 non-null  object\n",
      " 3   landing_page  290584 non-null  object\n",
      " 4   converted     290584 non-null  int64 \n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 13.3+ MB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>group</th>\n",
       "      <th>landing_page</th>\n",
       "      <th>converted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [user_id, timestamp, group, landing_page, converted]\n",
       "Index: []"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confirming the row has been drop\n",
    "print(df2.info())\n",
    "df2[df2.duplicated(['user_id'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">From the above cell, we can see that there are 290584 rows and that there are no duplicated user_id.\n",
    "\n",
    ">Alright, now we're ready to calculate the probabilities. We're going to check for the probability of\n",
    "- A user converting regardless of the page they recieved.\n",
    "- A user converting when he/she is shown the old landing page(i.e In the control group).\n",
    "- A user converting when he/she is shown the new landing page (ie In the treatment group).\n",
    "- A user being shown the new landing page and the old landing page.\n",
    "\n",
    "**Probability of a user converting regardless of page shown.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11959708724499628"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Probability of conversion\n",
    "prob_conv = df2.converted.mean()\n",
    "prob_conv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">The probability of a user converting is approximately **12%**\n",
    "\n",
    ">Our next calculation is the probability of conversion when in the control group, ie he/she is shown the old landing page.\n",
    "\n",
    "**Probability of a user converting when in control group**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1203863045004612"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "control_prob_conv = df2.query('group == \"control\"')['converted'].mean()\n",
    "control_prob_conv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> From the immediate cell above, we got that the probability of a user being converted when in the control group, shown the old landing page, is also approximately **12%**. Based on this and the probability of the overall conversion being 12%, it is safe to assume that the probability of a user converting when in the treatment group is also approximately 12%. However let's check our assumptions.\n",
    "\n",
    "**Probability of a user converting when in treatment group**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11880806551510564"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "treat_prob_conv = df2.query('group == \"treatment\"')['converted'].mean()\n",
    "treat_prob_conv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> We got our assumption right in that the probability of a user converting while in the treatment group is approximately **12%**. However, before we can claim that a user will convert regardless of the group is 12%, we need to know the probability of a user being placed in the control group and the probability of being placed in the treatment group.\n",
    "\n",
    "**Probability of a user being placed in the control group**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4999380557773312"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_cont_grp = df2.query('group == \"control\"')['group'].count()/df2.shape[0]\n",
    "prob_cont_grp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5000619442226688"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_treat_grp = 1 - prob_cont_grp\n",
    "prob_treat_grp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">The probability of being placed in one of the groups in approximately 0.5 which is fair and not biased. Therefore we can say that there is no significant change in the conversion rate if the new landing page is adopted. \n",
    "\n",
    "In the next part, we'd run a hypothesis test with a type 1 error rate of 5%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='ab_test'></a>\n",
    "### Part II - A/B Test\n",
    "\n",
    "> It should be noted that due to the time stamp associated with each event, a hypothesis test could technically be ran continuously as each observation was observed. However, then the hard question is do we stop as soon as one page is considered significantly better than another or does it need to happen consistently for a certain amount of time? How long do we run to render a decision that neither page is better than another?\n",
    "\n",
    ">These questions are the difficult parts associated with A/B tests in general.\n",
    "\n",
    "> For now, let us consider that we need to make the decision based on all the data provided. We want to assume that the old page is better unless the new page proves to be definitely better at a Type I error rate of 5%. In doing this, we need to state our null and alternative hypothesis. We can state our hypothesis in terms of words or in terms of  $p_{old}$  and $p_{new}$, which are the converted rates for the old and new pages respectively.\n",
    "\n",
    "$$H_0: P_{new} - P_{old} \\leq 0$$\n",
    "$$H_1: P_{new} - P_{old} > 0$$\n",
    "\n",
    "\n",
    "Let's assume that under the null hypothesis,  $p_{new}$ and $p_{old}$  both have \"true\" success rates equal to the converted success rate regardless of page - that is  $p_{new}$ and $p_{old}$ are equal. Furthermore, we assume they are equal to the converted rate in ab_data.csv regardless of the page, we would use a sample size for each page equal to the one in **ab_data.csv**. \n",
    "\n",
    "Let's perform the sampling distribution for the difference in converted between the two pages over 10,000 iterations of calculating an estimate from the null."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>group</th>\n",
       "      <th>landing_page</th>\n",
       "      <th>converted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>112524</th>\n",
       "      <td>784794</td>\n",
       "      <td>2017-01-22 01:34:36.000130</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159561</th>\n",
       "      <td>663734</td>\n",
       "      <td>2017-01-10 09:54:07.410504</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257900</th>\n",
       "      <td>717822</td>\n",
       "      <td>2017-01-04 22:02:49.467009</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200235</th>\n",
       "      <td>788175</td>\n",
       "      <td>2017-01-07 07:37:22.996928</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240424</th>\n",
       "      <td>810919</td>\n",
       "      <td>2017-01-05 06:23:45.980823</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118385</th>\n",
       "      <td>846179</td>\n",
       "      <td>2017-01-11 21:50:45.119106</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235730</th>\n",
       "      <td>818981</td>\n",
       "      <td>2017-01-05 14:13:30.129946</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id                   timestamp      group landing_page  converted\n",
       "112524   784794  2017-01-22 01:34:36.000130    control     old_page          0\n",
       "159561   663734  2017-01-10 09:54:07.410504  treatment     new_page          0\n",
       "257900   717822  2017-01-04 22:02:49.467009    control     old_page          1\n",
       "200235   788175  2017-01-07 07:37:22.996928  treatment     new_page          0\n",
       "240424   810919  2017-01-05 06:23:45.980823  treatment     new_page          0\n",
       "118385   846179  2017-01-11 21:50:45.119106    control     old_page          1\n",
       "235730   818981  2017-01-05 14:13:30.129946    control     old_page          0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To get started we'll view a sample of the dataset\n",
    "df2.sample(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've viewed a sample of the data let's calculate the conversion rate for $p_{new}$ under the null."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11959708724499628"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Coversion rate for new page under the null\n",
    "p_new = df2['converted'].mean()\n",
    "p_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result above shows that the conversion rate for the new page is approximately 12%. \n",
    "\n",
    "And as we have done for $P_{new}$, we would also calculate the conversion rate for the old page $P_{old}$ under the null."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11959708724499628"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Conversion rate for the old page under the null.\n",
    "p_old = df2['converted'].mean()\n",
    "p_old"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The conversion rate for the old page under the null is same, 11.96%, as that of the new page under the floor. It should be noted that under the null, the rate of conversion for the new page and old page is probability that a page is converted.\n",
    "\n",
    "Next, we check for the number of individuals in both groups, that is the individuals shown the new page($n_{new}$) and those shown the old page($n_{old}$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "145310"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of individuals shown the new page\n",
    "n_new = df2.query('landing_page == \"new_page\"').shape[0]\n",
    "n_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "145274"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of individuals shown the old page\n",
    "n_old = df2.query('landing_page == \"old_page\"').shape[0]\n",
    "n_old"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above two cells, we get that **145,310** and **145,274** people were the new page ond old page respectively.\n",
    "We can see that both groups have approximately a hundred and forty-five participants each.\n",
    "\n",
    "The next step we'd do is to simulate $n_{new}$ (number of participants) transactions with a conversion rate of $P_{new}$ under the null and store these $n_{new}$  1's and 0's in **new_page_converted**. We'd also do the same for the old page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulating n transactions with a conversion rate of p.\n",
    "new_page_converted = np.random.choice(2, size=n_new, p=[p_new, 1-p_new])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulating n_old transactions with a conversion rate of p_old\n",
    "old_page_converted = np.random.choice(2, size=n_old, p=[p_old, 1-p_old])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'd check for the difference of $p_{new}$ and $p_{old}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_new - p_old"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create 10,000  $p_{new}$  -  $p_{old}$  values using the same simulation process we used above and store all 10,000 values in a NumPy array called p_diffs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.21149905e-04, 1.53949322e-03, 2.35878335e-03, ...,\n",
       "       2.07648982e-03, 1.15033019e-05, 1.07841002e-03])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_diffs = []\n",
    "new_convert = np.random.binomial(n_new,p_new,10000)/n_new\n",
    "old_convert = np.random.binomial(n_old,p_old,10000)/n_old\n",
    "p_diffs = new_convert - old_convert\n",
    "p_diffs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've used the simulation process and stored the difference in an array, let's plot a histogram of the p_diffs. Does this plot look like what we expected?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(p_diffs);\n",
    "plt.title('Conversion Probability.');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next 3 steps or so will provide us with the p-value of the test. **The p-value is the evidence we use to either fail to reject to reject the null hypothesis or reject our null hypothesis.**\n",
    "\n",
    "The p-value is the proportion of the p_diffs that are greater than the actual difference observed in **ab_data.csv** and to do that we need to find the observed difference in ab_data.csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0015782389853555567"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Observed difference in ab_data.csv\n",
    "obs_diff = treat_prob_conv - control_prob_conv\n",
    "obs_diff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The observed difference is -0.001578.\n",
    "\n",
    "The next step is to find the p-value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting the observed difference on the histogram\n",
    "plt.hist(p_diffs);\n",
    "plt.axvline(obs_diff, color='red');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.906"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# P-value\n",
    "(p_diffs > obs_diff).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The p-value is 0.9044. Since our p-value is greater than our type 1 error rate of 0.05 (5%), we fail to rejejct the null hypothesis which means we should not go with the new page and stick with the old page instead.**\n",
    "\n",
    "We could also use a built-in to achieve similar results. Though using the built-in might be easier to code, the above portions are a walkthrough of the ideas that are critical to correctly thinking about statistical significance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "convert_old = df2.query(\" landing_page == 'old_page' and converted == 1\").shape[0]\n",
    "convert_new = df2.query(\" landing_page == 'new_page' and converted == 1\").shape[0]\n",
    "n_old = len(df2.query('landing_page == \"old_page\"'))\n",
    "n_new = len(df2.query('landing_page == \"new_page\"'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After initializing the variables, we would use the *proportion_ztest* to compute the p-value and the z-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.3109241984234394, 0.9050583127590245)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from statsmodels.stats.proportion import proportions_ztest\n",
    "\n",
    "count = np.array([convert_old, convert_new])\n",
    "nobs = np.array([n_old, n_new])\n",
    "\n",
    "zstat, pval = proportions_ztest(count, nobs, alternative='smaller') # alternative=Larger cos alt hypothesis p_new > p_old\n",
    "zstat, pval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The z-score is 1.3109 and the p-value is 0.9051. The p-value agrees with the results we obtained above.**\n",
    "\n",
    "**The z-score is the value how many standard deviation our values are above or below the mean. A positive z-score means our values are above the mean and a negative z-score says our many standard deviation our data values are below the mean. A z-score of 0 means the values is same with the mean.**\n",
    "\n",
    "**The z-score obtained shows that our data values are 1.3109 standard deviations above the mean.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='regression'></a>\n",
    "### Part III - A Regression Approach.\n",
    "\n",
    "In this we will try to achieve the result we achieved in the A/B test in Part II above by performing regression.\n",
    "\n",
    "It should also be noted that **Logistic regression** will be performed because we are predicting only two possible outcomes. The goal is to use statsmodels to fit the logistic regression to see if there is a significant difference in conversion based on which page a customer receives.\n",
    "\n",
    "However, before we start, we need to create a new column for the intercept in df2. We'd also create a dummy variable column for which page each user received.\n",
    "\n",
    "As stated above, we'd add intercept column, as well as an ab_page column, which is 1 when an individual receives the treatment and 0 if control. We'd also get dummy  variables for the group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>group</th>\n",
       "      <th>landing_page</th>\n",
       "      <th>converted</th>\n",
       "      <th>intercept</th>\n",
       "      <th>ab_page</th>\n",
       "      <th>control</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>851104</td>\n",
       "      <td>2017-01-21 22:11:48.556739</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>804228</td>\n",
       "      <td>2017-01-12 08:01:45.159739</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>864975</td>\n",
       "      <td>2017-01-21 01:52:26.210827</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>936923</td>\n",
       "      <td>2017-01-10 15:20:49.083499</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>719014</td>\n",
       "      <td>2017-01-17 01:48:29.539573</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                   timestamp    group landing_page  converted  \\\n",
       "0   851104  2017-01-21 22:11:48.556739  control     old_page          0   \n",
       "1   804228  2017-01-12 08:01:45.159739  control     old_page          0   \n",
       "4   864975  2017-01-21 01:52:26.210827  control     old_page          1   \n",
       "5   936923  2017-01-10 15:20:49.083499  control     old_page          0   \n",
       "7   719014  2017-01-17 01:48:29.539573  control     old_page          0   \n",
       "\n",
       "   intercept  ab_page  control  \n",
       "0          1        1        0  \n",
       "1          1        1        0  \n",
       "4          1        1        0  \n",
       "5          1        1        0  \n",
       "7          1        1        0  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adding an intercept column and a dummy variable\n",
    "import statsmodels.api as sm \n",
    "\n",
    "df2['intercept'] = 1 # Create Intercept\n",
    "df2[['ab_page', 'control']] = pd.get_dummies(df2['group']) # Get dummy variables for group\n",
    "\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the intercept and dummy column. However, we'd drop the control column as when the ab_page reads zero it means the control is one. It's only a column that is needed really."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>group</th>\n",
       "      <th>landing_page</th>\n",
       "      <th>converted</th>\n",
       "      <th>intercept</th>\n",
       "      <th>ab_page</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>169960</th>\n",
       "      <td>670426</td>\n",
       "      <td>2017-01-23 20:03:59.070604</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42311</th>\n",
       "      <td>804200</td>\n",
       "      <td>2017-01-21 01:55:34.841938</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101777</th>\n",
       "      <td>708491</td>\n",
       "      <td>2017-01-04 05:45:43.194072</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253695</th>\n",
       "      <td>916985</td>\n",
       "      <td>2017-01-03 19:06:10.740701</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123666</th>\n",
       "      <td>633990</td>\n",
       "      <td>2017-01-21 16:36:10.338798</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id                   timestamp      group landing_page  \\\n",
       "169960   670426  2017-01-23 20:03:59.070604    control     old_page   \n",
       "42311    804200  2017-01-21 01:55:34.841938  treatment     new_page   \n",
       "101777   708491  2017-01-04 05:45:43.194072  treatment     new_page   \n",
       "253695   916985  2017-01-03 19:06:10.740701  treatment     new_page   \n",
       "123666   633990  2017-01-21 16:36:10.338798  treatment     new_page   \n",
       "\n",
       "        converted  intercept  ab_page  \n",
       "169960          1          1        1  \n",
       "42311           0          1        0  \n",
       "101777          0          1        0  \n",
       "253695          0          1        0  \n",
       "123666          0          1        0  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dropping a column as only one is really needed\n",
    "df2 = df2.drop(['control'], axis=1)\n",
    "df2.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the sample above, we can see that when shown the new landing page, the ab_page reads 0(zero) which can make us confirm that the control column would have read 1(one). The opposite is the case when shown the old landing page which helps us in the argument that the control column was not needed.\n",
    "\n",
    "Going forward, we'd use **statsmodels** to instantiate our regression model on the two columns (intercept, ab_page) we created above and then fit the model using the two columns to predict whether or not an individual converts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.366118\n",
      "         Iterations 6\n"
     ]
    }
   ],
   "source": [
    "logit = sm.Logit(df2['converted'], df2[['intercept', 'ab_page']]) # Instatiating our regression model\n",
    "results = logit.fit() # Fitting the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to provide a summary of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td>Model:</td>              <td>Logit</td>      <td>Pseudo R-squared:</td>    <td>0.000</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <td>Dependent Variable:</td>     <td>converted</td>          <td>AIC:</td>        <td>212780.3502</td>\n",
       "</tr>\n",
       "<tr>\n",
       "         <td>Date:</td>        <td>2021-01-20 01:58</td>       <td>BIC:</td>        <td>212801.5095</td>\n",
       "</tr>\n",
       "<tr>\n",
       "   <td>No. Observations:</td>       <td>290584</td>       <td>Log-Likelihood:</td>  <td>-1.0639e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "       <td>Df Model:</td>              <td>1</td>            <td>LL-Null:</td>      <td>-1.0639e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "     <td>Df Residuals:</td>         <td>290582</td>        <td>LLR p-value:</td>      <td>0.18988</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "      <td>Converged:</td>           <td>1.0000</td>           <td>Scale:</td>         <td>1.0000</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "    <td>No. Iterations:</td>        <td>6.0000</td>              <td></td>               <td></td>      \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>       <th>Coef.</th>  <th>Std.Err.</th>     <th>z</th>      <th>P>|z|</th> <th>[0.025</th>  <th>0.975]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intercept</th> <td>-2.0038</td>  <td>0.0081</td>  <td>-247.1457</td> <td>0.0000</td> <td>-2.0197</td> <td>-1.9879</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ab_page</th>   <td>0.0150</td>   <td>0.0114</td>   <td>1.3109</td>   <td>0.1899</td> <td>-0.0074</td> <td>0.0374</td> \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary2.Summary'>\n",
       "\"\"\"\n",
       "                          Results: Logit\n",
       "==================================================================\n",
       "Model:              Logit            Pseudo R-squared: 0.000      \n",
       "Dependent Variable: converted        AIC:              212780.3502\n",
       "Date:               2021-01-20 01:58 BIC:              212801.5095\n",
       "No. Observations:   290584           Log-Likelihood:   -1.0639e+05\n",
       "Df Model:           1                LL-Null:          -1.0639e+05\n",
       "Df Residuals:       290582           LLR p-value:      0.18988    \n",
       "Converged:          1.0000           Scale:            1.0000     \n",
       "No. Iterations:     6.0000                                        \n",
       "-------------------------------------------------------------------\n",
       "              Coef.   Std.Err.      z      P>|z|    [0.025   0.975]\n",
       "-------------------------------------------------------------------\n",
       "intercept    -2.0038    0.0081  -247.1457  0.0000  -2.0197  -1.9879\n",
       "ab_page       0.0150    0.0114     1.3109  0.1899  -0.0074   0.0374\n",
       "==================================================================\n",
       "\n",
       "\"\"\""
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Providing summary of results\n",
    "results.summary2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We can see that the p-value associated with the ab-page is 0.1899 and what we got part II is 0.9051. These values differ  because in Logistic Regression model, we are comparing the two samples whereas in the AB Test we were comparing just one sample, that is to confirm whether to go with the old page or not.**\n",
    "\n",
    "**The p-value of 0.1899 can also be interpreted as the ab_page (being in treatment or control group) is not statistically significant for predicting if the new page will convert an individual or not.**\n",
    "\n",
    "**The pages only cannot be used to determine whether an individual will convert or not as some other factors such as age, gender might play a role in deciding.\n",
    "However there might be disadvantages to adding more variables to our model in that the variables may not have a correlation to our results.**\n",
    "\n",
    "Okay, now we would add countries as a variable in our test. The first step wil be to read in the countries dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>834778</td>\n",
       "      <td>UK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>928468</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>822059</td>\n",
       "      <td>UK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>711597</td>\n",
       "      <td>UK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>710616</td>\n",
       "      <td>UK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id country\n",
       "0   834778      UK\n",
       "1   928468      US\n",
       "2   822059      UK\n",
       "3   711597      UK\n",
       "4   710616      UK"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in countries.csv\n",
    "country_df = pd.read_csv('countries.csv')\n",
    "country_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are only 2 columns, the user_id and the country column. We'd try to get more information about the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 290584 entries, 0 to 290583\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count   Dtype \n",
      "---  ------   --------------   ----- \n",
      " 0   user_id  290584 non-null  int64 \n",
      " 1   country  290584 non-null  object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 4.4+ MB\n"
     ]
    }
   ],
   "source": [
    "country_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As noted before, there are two columnn. We now know that there are 290,583 rows which is less than the ab_test dataset.\n",
    "\n",
    "Now, let's check the unique entries in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id    290584\n",
       "country         3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unique entries in the dataset\n",
    "country_df.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are three unique countries in the dataset, so it'd be nice to know the third (we already know of The US and UK). Also, though the country dataset contains less rows than the ab_test dataset, the number of unique_id is same so we can go on with our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['UK', 'US', 'CA'], dtype=object)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unique countries\n",
    "country_df['country'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now know the third country. It's Canada!!!\n",
    "\n",
    "Up next: Combine the datasets. We're going to combine it on the user_id as both datasets have the same sets of unique id. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>group</th>\n",
       "      <th>landing_page</th>\n",
       "      <th>converted</th>\n",
       "      <th>intercept</th>\n",
       "      <th>ab_page</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>851104</td>\n",
       "      <td>2017-01-21 22:11:48.556739</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>804228</td>\n",
       "      <td>2017-01-12 08:01:45.159739</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>864975</td>\n",
       "      <td>2017-01-21 01:52:26.210827</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>936923</td>\n",
       "      <td>2017-01-10 15:20:49.083499</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>719014</td>\n",
       "      <td>2017-01-17 01:48:29.539573</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                   timestamp    group landing_page  converted  \\\n",
       "0   851104  2017-01-21 22:11:48.556739  control     old_page          0   \n",
       "1   804228  2017-01-12 08:01:45.159739  control     old_page          0   \n",
       "4   864975  2017-01-21 01:52:26.210827  control     old_page          1   \n",
       "5   936923  2017-01-10 15:20:49.083499  control     old_page          0   \n",
       "7   719014  2017-01-17 01:48:29.539573  control     old_page          0   \n",
       "\n",
       "   intercept  ab_page country  \n",
       "0          1        1      US  \n",
       "1          1        1      US  \n",
       "4          1        1      US  \n",
       "5          1        1      US  \n",
       "7          1        1      US  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine the datasets.\n",
    "df_new = df2.join(country_df.set_index('user_id'), on='user_id')\n",
    "df_new.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Woohoo!!! That went well. Next in our analysis is to create an intercept column and get dummy variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intercept and dummy variables.\n",
    "df_new['intercept'] = 1\n",
    "df_new[['ca', 'uk', 'us']] = pd.get_dummies(df_new['country']) # Get dummy variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You know what's next right?\n",
    "Yes you do.\n",
    "we'd use statsmodels to instantiate our regression model on the intercept and country columns and then fit the model using the two columns to predict whether or not an individual converts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.366116\n",
      "         Iterations 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td>Model:</td>              <td>Logit</td>      <td>Pseudo R-squared:</td>    <td>0.000</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <td>Dependent Variable:</td>     <td>converted</td>          <td>AIC:</td>        <td>212780.8333</td>\n",
       "</tr>\n",
       "<tr>\n",
       "         <td>Date:</td>        <td>2021-01-20 01:58</td>       <td>BIC:</td>        <td>212812.5723</td>\n",
       "</tr>\n",
       "<tr>\n",
       "   <td>No. Observations:</td>       <td>290584</td>       <td>Log-Likelihood:</td>  <td>-1.0639e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "       <td>Df Model:</td>              <td>2</td>            <td>LL-Null:</td>      <td>-1.0639e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "     <td>Df Residuals:</td>         <td>290581</td>        <td>LLR p-value:</td>      <td>0.19835</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "      <td>Converged:</td>           <td>1.0000</td>           <td>Scale:</td>         <td>1.0000</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "    <td>No. Iterations:</td>        <td>6.0000</td>              <td></td>               <td></td>      \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>       <th>Coef.</th>  <th>Std.Err.</th>     <th>z</th>      <th>P>|z|</th> <th>[0.025</th>  <th>0.975]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intercept</th> <td>-1.9868</td>  <td>0.0114</td>  <td>-174.1736</td> <td>0.0000</td> <td>-2.0092</td> <td>-1.9645</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ca</th>        <td>-0.0507</td>  <td>0.0284</td>   <td>-1.7863</td>  <td>0.0740</td> <td>-0.1064</td> <td>0.0049</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>us</th>        <td>-0.0099</td>  <td>0.0133</td>   <td>-0.7458</td>  <td>0.4558</td> <td>-0.0360</td> <td>0.0161</td> \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary2.Summary'>\n",
       "\"\"\"\n",
       "                          Results: Logit\n",
       "==================================================================\n",
       "Model:              Logit            Pseudo R-squared: 0.000      \n",
       "Dependent Variable: converted        AIC:              212780.8333\n",
       "Date:               2021-01-20 01:58 BIC:              212812.5723\n",
       "No. Observations:   290584           Log-Likelihood:   -1.0639e+05\n",
       "Df Model:           2                LL-Null:          -1.0639e+05\n",
       "Df Residuals:       290581           LLR p-value:      0.19835    \n",
       "Converged:          1.0000           Scale:            1.0000     \n",
       "No. Iterations:     6.0000                                        \n",
       "-------------------------------------------------------------------\n",
       "              Coef.   Std.Err.      z      P>|z|    [0.025   0.975]\n",
       "-------------------------------------------------------------------\n",
       "intercept    -1.9868    0.0114  -174.1736  0.0000  -2.0092  -1.9645\n",
       "ca           -0.0507    0.0284    -1.7863  0.0740  -0.1064   0.0049\n",
       "us           -0.0099    0.0133    -0.7458  0.4558  -0.0360   0.0161\n",
       "==================================================================\n",
       "\n",
       "\"\"\""
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit2 = sm.Logit(df_new['converted'], df_new[['intercept', 'ca', 'us']]) # Using UK as baseline\n",
    "results2 = logit2.fit()\n",
    "results2.summary2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sadly, from the p-values of both Canada and US, 0.0740 and 0.4558 respectively, we cannot say the country of the user is a statistically significant factor in conversion or not.\n",
    "\n",
    "Moving ahead, we would now like to look at an interaction between page and country to see if there significant effects on conversion. What this means is that we would create additional columns specifying country and conversion.\n",
    "\n",
    "And guess what, we'd instatiate our regression model and fit it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create additional columns specifying country and conversion.\n",
    "df_new['us_ab_page'] = df_new['us'] * df_new['ab_page']\n",
    "df_new['ca_ab_page'] = df_new['ca'] * df_new['ab_page']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.366109\n",
      "         Iterations 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td>Model:</td>              <td>Logit</td>      <td>Pseudo R-squared:</td>    <td>0.000</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <td>Dependent Variable:</td>     <td>converted</td>          <td>AIC:</td>        <td>212782.6602</td>\n",
       "</tr>\n",
       "<tr>\n",
       "         <td>Date:</td>        <td>2021-01-20 01:58</td>       <td>BIC:</td>        <td>212846.1381</td>\n",
       "</tr>\n",
       "<tr>\n",
       "   <td>No. Observations:</td>       <td>290584</td>       <td>Log-Likelihood:</td>  <td>-1.0639e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "       <td>Df Model:</td>              <td>5</td>            <td>LL-Null:</td>      <td>-1.0639e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "     <td>Df Residuals:</td>         <td>290578</td>        <td>LLR p-value:</td>      <td>0.19199</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "      <td>Converged:</td>           <td>1.0000</td>           <td>Scale:</td>         <td>1.0000</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "    <td>No. Iterations:</td>        <td>6.0000</td>              <td></td>               <td></td>      \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "       <td></td>       <th>Coef.</th>  <th>Std.Err.</th>     <th>z</th>      <th>P>|z|</th> <th>[0.025</th>  <th>0.975]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intercept</th>  <td>-1.9814</td>  <td>0.0161</td>  <td>-122.8600</td> <td>0.0000</td> <td>-2.0130</td> <td>-1.9498</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ab_page</th>    <td>-0.0108</td>  <td>0.0228</td>   <td>-0.4749</td>  <td>0.6349</td> <td>-0.0555</td> <td>0.0339</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ca</th>         <td>-0.0901</td>  <td>0.0405</td>   <td>-2.2252</td>  <td>0.0261</td> <td>-0.1694</td> <td>-0.0107</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>us</th>         <td>-0.0257</td>  <td>0.0188</td>   <td>-1.3634</td>  <td>0.1728</td> <td>-0.0625</td> <td>0.0112</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ca_ab_page</th> <td>0.0783</td>   <td>0.0568</td>   <td>1.3783</td>   <td>0.1681</td> <td>-0.0330</td> <td>0.1896</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>us_ab_page</th> <td>0.0314</td>   <td>0.0266</td>   <td>1.1807</td>   <td>0.2377</td> <td>-0.0207</td> <td>0.0835</td> \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary2.Summary'>\n",
       "\"\"\"\n",
       "                          Results: Logit\n",
       "==================================================================\n",
       "Model:              Logit            Pseudo R-squared: 0.000      \n",
       "Dependent Variable: converted        AIC:              212782.6602\n",
       "Date:               2021-01-20 01:58 BIC:              212846.1381\n",
       "No. Observations:   290584           Log-Likelihood:   -1.0639e+05\n",
       "Df Model:           5                LL-Null:          -1.0639e+05\n",
       "Df Residuals:       290578           LLR p-value:      0.19199    \n",
       "Converged:          1.0000           Scale:            1.0000     \n",
       "No. Iterations:     6.0000                                        \n",
       "-------------------------------------------------------------------\n",
       "              Coef.   Std.Err.      z      P>|z|    [0.025   0.975]\n",
       "-------------------------------------------------------------------\n",
       "intercept    -1.9814    0.0161  -122.8600  0.0000  -2.0130  -1.9498\n",
       "ab_page      -0.0108    0.0228    -0.4749  0.6349  -0.0555   0.0339\n",
       "ca           -0.0901    0.0405    -2.2252  0.0261  -0.1694  -0.0107\n",
       "us           -0.0257    0.0188    -1.3634  0.1728  -0.0625   0.0112\n",
       "ca_ab_page    0.0783    0.0568     1.3783  0.1681  -0.0330   0.1896\n",
       "us_ab_page    0.0314    0.0266     1.1807  0.2377  -0.0207   0.0835\n",
       "==================================================================\n",
       "\n",
       "\"\"\""
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit3 = sm.Logit(df_new['converted'], df_new[['intercept', 'ab_page', 'ca', 'us', 'ca_ab_page', 'us_ab_page']]) \n",
    "# UK is the baseline.\n",
    "results3 = logit3.fit()\n",
    "results3.summary2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright, what do we get?\n",
    "\n",
    "**We got the p-value of Canada to be less than our Type I error of 0.05, which means that it is statistically significant in going with the alternate hypothesis that the second page might convert more users based in Canada.**\n",
    "\n",
    "**However, all other p-values are greater than 0.05 implying that they are not statistically signigicant is conversion of users.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='conclusions'></a>\n",
    "### Part IV - Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The conclusion of the whole study and the general result is that we do not have sufficient evidence to suggest that the new page results in more conversions than the old one.**\n",
    "\n",
    "**Practically too, there is no evidence to reject the null hypothesis as there is no significant conversion for users are shown the new page.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
